{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c8c20eb-6eb2-4671-81cd-7f79b2626336",
   "metadata": {},
   "source": [
    "# 04.4- Agents\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec61215-ed31-4b9c-995e-9de92724b5f6",
   "metadata": {},
   "source": [
    "Let's take a look at agents, and expand the capabilities of LLMs.\n",
    "\n",
    "### AgentType\n",
    "\n",
    "There are several types of agents, each optimized for what we need. An agent can store past chat information or can enforce each call to the LLM as an independent one.  \n",
    "It is up to you to decide what you need in your future projects, but here we will focus on agents capable of maintaining a chat.\n",
    "\n",
    "### Tools\n",
    "\n",
    "The `tools` are a set of options one uses to give further capabilities to the agent: parsing wikipedia, using google for searches, etc..  \n",
    "Several models are trained with a 1-2 year delay in data, like chatgpt-3.5. It was only trained with data up to 2022. Some tools may help to overcome this limitation with active searches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4309966-964c-40f9-a053-ced7e1da69c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numexpr\n",
    "#!pip install langchainhub\n",
    "#!pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f094e5d1-6fd6-44b3-940d-f1918e88039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType # The type of agent\n",
    "from langchain.memory import ConversationBufferMemory # Memory\n",
    "from langchain.agents import initialize_agent \n",
    "from langchain.agents import load_tools #Additional tools\n",
    "from langchain_openai import ChatOpenAI # Our LLM\n",
    "from IPython.display import Markdown #Pretty display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94c834e8-8817-4798-95db-8792d71824bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a memory instance for our agent\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bce465fb-ad2d-41ae-9471-d7c4c2a89439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luisg\\anaconda3\\envs\\llm\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm=ChatOpenAI(temperature=0.1)\n",
    "tools = load_tools([\"llm-math\"], llm=llm) \n",
    "agent_chain = initialize_agent(tools, \n",
    "                               llm,\n",
    "                               agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION, \n",
    "                               verbose=True, \n",
    "                               memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3791ea70-c744-48bd-8a23-55156a0d16f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "AI: Some popular Portuguese food recipes include Bacalhau à Brás (salted cod with potatoes and eggs), Caldo Verde (kale soup), and Pastéis de Nata (custard tarts). Would you like more information on any specific recipe?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "answer = agent_chain.invoke(input=\"What are some good Portuguese food recipes?\", handle_parsing_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6dd2d7b-4c2e-4a8a-9488-27298d88813a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Some popular Portuguese food recipes include Bacalhau à Brás (salted cod with potatoes and eggs), Caldo Verde (kale soup), and Pastéis de Nata (custard tarts). Would you like more information on any specific recipe?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(answer['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b533f508-d8f6-4f85-99f6-cecdd790d0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luisg\\anaconda3\\envs\\llm\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: Calculator\n",
      "Action Input: Fat content of Bacalhau à Brás, Caldo Verde, and Pastéis de Nata\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 43\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
      "AI: The dish with the least fat content among Bacalhau à Brás, Caldo Verde, and Pastéis de Nata is Caldo Verde, which is a kale soup.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "answer = agent_chain.run(\"Which one of those dishes has the least fat?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6c1edb-1251-47a1-a70b-912b587cfbb0",
   "metadata": {},
   "source": [
    "Now the history of our conversation is stored and you can build upon what you have chatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f97ccc92-c806-4fda-860a-01a357cfb32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: Calculator\n",
      "Action Input: Calculate grocery shopping list for Caldo Verde recipe\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 6.5\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
      "AI: Here is a grocery shopping list for making Caldo Verde:\n",
      "- Kale\n",
      "- Potatoes\n",
      "- Onion\n",
      "- Garlic\n",
      "- Chorizo (optional)\n",
      "- Olive oil\n",
      "- Salt\n",
      "- Water\n",
      "\n",
      "These are the main ingredients you will need to make a delicious Caldo Verde soup. Enjoy your cooking!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Here is a grocery shopping list for making Caldo Verde:\\n- Kale\\n- Potatoes\\n- Onion\\n- Garlic\\n- Chorizo (optional)\\n- Olive oil\\n- Salt\\n- Water\\n\\nThese are the main ingredients you will need to make a delicious Caldo Verde soup. Enjoy your cooking!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(\"Give me a grocery shopping list to make that dish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3d9e24-e04e-4b81-8e35-75292bf7249b",
   "metadata": {},
   "source": [
    "---\n",
    "### Other applications: Analyzing documents\n",
    "\n",
    "The Langchain framework has a lot of code already specialized in tasks meant to be done over and over.  \n",
    "In this example we go over a text file that we have seen before, the play from William Shakespeare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4faef37c-450c-4248-9d42-277002840159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Let's get our Shakespeare back\n",
    "response = requests.get(\"https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\")\n",
    "\n",
    "# There is a size limit for inputs\n",
    "shakespeare = response.text[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50685233-e7b9-4c15-a9f3-3b50506b2d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import AnalyzeDocumentChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ebe9777-1727-447b-b584-61c2820237da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "qa_chain = load_qa_chain(llm)\n",
    "qa_document_chain = AnalyzeDocumentChain(combine_docs_chain=qa_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7bd9723-a583-4246-8f82-2d379a5b5b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The text provided is an excerpt from the play \"Coriolanus\" by William Shakespeare. It is a tragedy believed to have been written between 1605 and 1608.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_document_chain.run(\n",
    "    input_document=shakespeare,\n",
    "    question=\"What is this work?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92712444-da25-4b58-9984-8b943e3b594b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The main protagonist of this work is Caius Marcius, also known as Coriolanus. He is a Roman general who is initially portrayed as proud and disdainful of the common people. He is a skilled warrior and is respected for his military prowess. However, his arrogance and contempt for the lower classes lead to conflict and ultimately his downfall.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_document_chain.run(\n",
    "    input_document=shakespeare,\n",
    "    question=\"Describe the main protagonist of this work.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403505a8-6af4-4486-879e-27487d769477",
   "metadata": {},
   "source": [
    "---\n",
    "### PDF documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25992325-fb0a-4118-958d-1f3ac21514b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pypdf\n",
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b30d39e-1f22-4d03-bbcb-44689fada261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows\n",
    "#!cURL https://media.wizards.com/images/magic/resources/rules/EN_MTGM14_PrintedRulebook_LR.pdf >> EN_MTGM14_PrintedRulebook_LR.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d3e160-f6db-44eb-a6cb-6e7bd7f26ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAC/Linux\n",
    "#!wget https://media.wizards.com/images/magic/resources/rules/EN_MTGM14_PrintedRulebook_LR.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d6cc19-956f-4de0-ac88-d498f5fc6a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"EN_MTGM14_PrintedRulebook_LR.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0248b97f-fe61-41fc-8420-f5b3b2978a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9002086-56af-4967-a6fb-1d6b05cc68ae",
   "metadata": {},
   "source": [
    "A PDF is usually text+images. Ideally, you send both the images and the the text to the model for analysis.  \n",
    "But you need a multi-modal model for that, which we will not cover due to time constraints.  \n",
    "Here, we are just going to get the text and run some simple queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44738e90-800a-4552-bfa1-789d359f532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages[10].to_json()['kwargs']['page_content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a264b13a-53c8-43f4-9a7e-a5dabfc55e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "\n",
    "# Append all pages on a list and then join all list elements\n",
    "for page in pages:\n",
    "    text.append(page.to_json()['kwargs']['page_content'])\n",
    "\n",
    "all_text = '\\n'.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921dcad4-899c-4e7b-b0f3-fc640d2da8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of pages, number of characters\n",
    "len(text), len(all_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc71d87-5552-4ce6-ad22-143c13f79760",
   "metadata": {},
   "source": [
    "The document is too big for our model, we need to focus on some pages only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cc95bf-8d47-4376-9b5d-d03530899e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "\n",
    "# Append all pages on a list and then join all list elements\n",
    "for pagenumber in range(2,6):\n",
    "    text.append(pages[pagenumber].to_json()['kwargs']['page_content'])\n",
    "\n",
    "all_text = '\\n'.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f30f391-5863-4a58-a145-ea761bdf7156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of pages, number of characters\n",
    "len(text), len(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcad0fc-0091-4483-b43a-856e5bfc2e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492a60ec-09ea-4068-96c8-4b288ec51035",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = qa_document_chain.run(input_document=all_text,\n",
    "                               question=\"What are the parts of a card?\",)\n",
    "\n",
    "Markdown(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e088e0c8-f505-4ffa-9471-9ce0cea659c4",
   "metadata": {},
   "source": [
    "To analyse more content, one must use models capable of handling more tokens."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
